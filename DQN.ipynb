{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gym_graph\n",
    "import gym\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "WINDOW_LENGTH = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"Environment reset\")? (graph_env.py, line 136)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2963\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-3-84115f7470a8>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    env = gym.make(\"simple-static-graph-v0\")\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.6/site-packages/gym/envs/registration.py\"\u001b[0m, line \u001b[1;32m167\u001b[0m, in \u001b[1;35mmake\u001b[0m\n    return registry.make(id)\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.6/site-packages/gym/envs/registration.py\"\u001b[0m, line \u001b[1;32m119\u001b[0m, in \u001b[1;35mmake\u001b[0m\n    env = spec.make()\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.6/site-packages/gym/envs/registration.py\"\u001b[0m, line \u001b[1;32m85\u001b[0m, in \u001b[1;35mmake\u001b[0m\n    cls = load(self._entry_point)\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.6/site-packages/gym/envs/registration.py\"\u001b[0m, line \u001b[1;32m14\u001b[0m, in \u001b[1;35mload\u001b[0m\n    result = entry_point.load(False)\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.6/site-packages/pkg_resources/__init__.py\"\u001b[0m, line \u001b[1;32m2324\u001b[0m, in \u001b[1;35mload\u001b[0m\n    return self.resolve()\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.6/site-packages/pkg_resources/__init__.py\"\u001b[0m, line \u001b[1;32m2330\u001b[0m, in \u001b[1;35mresolve\u001b[0m\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n",
      "  File \u001b[1;32m\"/Users/scottfarley/Documents/rl-graph/gym_graph/envs/__init__.py\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from gym_graph.envs.simple_random import SimpleRandomEnv\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/scottfarley/Documents/rl-graph/gym_graph/envs/simple_random.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from gym_graph.envs.graph_env import GraphEnv\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/scottfarley/Documents/rl-graph/gym_graph/envs/graph_env.py\"\u001b[0;36m, line \u001b[0;32m136\u001b[0m\n\u001b[0;31m    print \"Environment reset\"\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"Environment reset\")?\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"simple-static-graph-v0\")\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initObs = env.reset()\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EnvProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        print (observation)\n",
    "        return observation\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        print (reward)\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (len(initObs),)\n",
    "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(1024))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions, activation=\"softmax\"))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
    "processor = EnvProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.05, value_test=.05,\n",
    "                              nb_steps=1000000)\n",
    "\n",
    "# The trade-off between exploration and exploitation is difficult and an on-going research topic.\n",
    "# If you want, you can experiment with the parameters or use a different policy. Another popular one\n",
    "# is Boltzmann-style exploration:\n",
    "# policy = BoltzmannQPolicy(tau=1.)\n",
    "# Feel free to give it a try!\n",
    "\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy, memory=memory,\n",
    "               nb_steps_warmup=50000, gamma=.99, target_model_update=10000,\n",
    "               train_interval=4, delta_clip=1.)\n",
    "dqn.compile(Adam(lr=.00025), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Okay, now it's time to learn something! We capture the interrupt exception so that training\n",
    "# can be prematurely aborted. Notice that you can the built-in Keras callbacks!\n",
    "weights_filename = 'dqn_{}_weights.h5f'.format(\"graph-v0\")\n",
    "checkpoint_weights_filename = 'dqn_graph-v0_weights_{step}.h5f'\n",
    "log_filename = 'dqn_{}_log.json'.format(\"graph-v0\")\n",
    "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000)]\n",
    "callbacks += [FileLogger(log_filename, interval=100)]\n",
    "dqn.fit(env, callbacks=callbacks, nb_steps=200000, log_interval=10000, verbose=2)\n",
    "\n",
    "# After training is done, we save the final weights one more time.\n",
    "dqn.save_weights(weights_filename, overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 10 episodes.\n",
    "dqn.test(env, nb_episodes=10, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
